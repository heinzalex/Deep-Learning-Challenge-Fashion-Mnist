{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Deep Learning Challenge Fashion Mnist",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDW6F8REwOCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZRVFznzJalV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "7e60e346-323e-4b34-8d79-bbaa9e1f41a2"
      },
      "source": [
        "# Note in Colab you can type \"pip install\" directly in the notebook\n",
        "!pip install tensorflow-gpu==2.0.0-rc1\n",
        "#!pip install -q -U tensorflow>=1.8.0\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Load the fashion-mnist pre-shuffled train data and test data\n",
        "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "print(\"x_train shape:\", X_train.shape, \"y_train shape:\", Y_train.shape, \"x_test shape:\", X_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0-rc1 in /usr/local/lib/python3.6/dist-packages (2.0.0rc1)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a20190807,>=1.15.0a20190806 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0a20190806)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.12.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.2.1)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.14.0.dev2019080601)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.3.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.18.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.30.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (49.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.1.0)\n",
            "x_train shape: (60000, 28, 28) y_train shape: (60000,) x_test shape: (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XotuxPfK0q3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "560cf90e-c25b-4a3d-bee2-d08ffc34d6c4"
      },
      "source": [
        "plt.imshow(X_train[0])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb290d78e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXeZlz89P6HC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = 784  # 28*28\n",
        "output_dim = nb_classes = 10\n",
        "nb_epoch = 20\n",
        "\n",
        "X_train = X_train.reshape(60000, input_dim)\n",
        "X_test = X_test.reshape(10000, input_dim)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9Iy373FP-wE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = to_categorical(Y_train, nb_classes)\n",
        "Y_test = to_categorical(Y_test, nb_classes)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjEbFTWZQ-c2",
        "colab_type": "text"
      },
      "source": [
        "Using 8 as the mini batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96z0sNaBK03K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfY1RsZQK052",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "4a3cd353-cb37-488d-ba66-5e616424d830"
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=8, epochs=20 , verbose=1)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb28a2672f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb28a2672f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 14s 238us/sample - loss: 0.5695 - accuracy: 0.8016\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 14s 231us/sample - loss: 0.4114 - accuracy: 0.8508\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 14s 233us/sample - loss: 0.3729 - accuracy: 0.8647\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 14s 228us/sample - loss: 0.3461 - accuracy: 0.8734\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 14s 229us/sample - loss: 0.3273 - accuracy: 0.8805\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 14s 230us/sample - loss: 0.3122 - accuracy: 0.8857\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 17s 280us/sample - loss: 0.2990 - accuracy: 0.8907\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 14s 236us/sample - loss: 0.2880 - accuracy: 0.8935\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 16s 260us/sample - loss: 0.2794 - accuracy: 0.8970\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 14s 230us/sample - loss: 0.2705 - accuracy: 0.8986\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 14s 232us/sample - loss: 0.2621 - accuracy: 0.9029\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 14s 227us/sample - loss: 0.2543 - accuracy: 0.9057\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 14s 229us/sample - loss: 0.2485 - accuracy: 0.9071\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 14s 229us/sample - loss: 0.2406 - accuracy: 0.9103\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 15s 244us/sample - loss: 0.2359 - accuracy: 0.9126\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 16s 264us/sample - loss: 0.2304 - accuracy: 0.9139\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 14s 233us/sample - loss: 0.2251 - accuracy: 0.9167\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 14s 228us/sample - loss: 0.2203 - accuracy: 0.9177\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 14s 235us/sample - loss: 0.2152 - accuracy: 0.9190\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 15s 258us/sample - loss: 0.2093 - accuracy: 0.9208\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb291e95f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAwVBpNORKf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0aa7bc2c-9fda-4302-9b63-4a099d9392bb"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.34087426557540895\n",
            "Test accuracy: 0.8817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUqYF23uRGPk",
        "colab_type": "text"
      },
      "source": [
        "Using 128 as the mini batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dERU2iOKK1AH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "5eb6faa4-8981-430d-abbe-c76a8eb494ce"
      },
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb286c412f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb286c412f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 1.1375 - accuracy: 0.6378\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.6712 - accuracy: 0.7796\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.5742 - accuracy: 0.8087\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.5276 - accuracy: 0.8210\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4998 - accuracy: 0.8288\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.4802 - accuracy: 0.8332\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.4642 - accuracy: 0.8378\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.4525 - accuracy: 0.8416\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4430 - accuracy: 0.8445\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4331 - accuracy: 0.8485\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4260 - accuracy: 0.8505\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4187 - accuracy: 0.8532\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4119 - accuracy: 0.8562\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.4059 - accuracy: 0.8578\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4003 - accuracy: 0.8601\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3950 - accuracy: 0.8622\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3914 - accuracy: 0.8640\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3870 - accuracy: 0.8645\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3823 - accuracy: 0.8665\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3777 - accuracy: 0.8684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb286c2e710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g4kgCiXK1E9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8c92382e-5e35-4931-89a1-41b4cd8e9ffa"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.42774833769798276\n",
            "Test accuracy: 0.8473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHb71LwmXq5a",
        "colab_type": "text"
      },
      "source": [
        "Add a few more hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIzHmUv0VpTA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "f9e1d9d2-1bc1-488f-ee7f-210d82277a3d"
      },
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(1024, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "# our third dense layer\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "# our fourth dense layer\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "# our fifth dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb285f7a7b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb285f7a7b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 14s 239us/sample - loss: 1.1432 - accuracy: 0.6407\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 14s 226us/sample - loss: 0.6051 - accuracy: 0.7905\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 13s 220us/sample - loss: 0.5119 - accuracy: 0.8202\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 13s 225us/sample - loss: 0.4724 - accuracy: 0.8342\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 14s 229us/sample - loss: 0.4446 - accuracy: 0.8436\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 14s 226us/sample - loss: 0.4239 - accuracy: 0.8499\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 13s 224us/sample - loss: 0.4078 - accuracy: 0.8556\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 14s 226us/sample - loss: 0.3936 - accuracy: 0.8608\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 13s 224us/sample - loss: 0.3803 - accuracy: 0.8657\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 13s 220us/sample - loss: 0.3724 - accuracy: 0.8678\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 13s 223us/sample - loss: 0.3600 - accuracy: 0.8726\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 14s 228us/sample - loss: 0.3521 - accuracy: 0.8737\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 13s 223us/sample - loss: 0.3435 - accuracy: 0.8769\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 13s 223us/sample - loss: 0.3363 - accuracy: 0.8805\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 14s 229us/sample - loss: 0.3296 - accuracy: 0.8812\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 14s 231us/sample - loss: 0.3216 - accuracy: 0.8846\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 13s 224us/sample - loss: 0.3138 - accuracy: 0.8872\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 13s 221us/sample - loss: 0.3097 - accuracy: 0.8886\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 13s 221us/sample - loss: 0.3050 - accuracy: 0.8893\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 13s 224us/sample - loss: 0.2981 - accuracy: 0.8918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb2855d84e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZJYcIewVpWs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a07c8af1-ae9f-4067-d443-669225f61934"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.35467272478342055\n",
            "Test accuracy: 0.8728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4roxhIzRY2Vt",
        "colab_type": "text"
      },
      "source": [
        "The added hidden layers performed better than the previous model with the same batch size with less hidden layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd2uTENKa7Mn",
        "colab_type": "text"
      },
      "source": [
        "Use Tanh activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBre_SkxaPzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "a5a3995d-45db-4365-f4d5-522b799c6359"
      },
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb27e65bae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb27e65bae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 1.0548 - accuracy: 0.6793\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.6489 - accuracy: 0.7873\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.5636 - accuracy: 0.8123\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 0.5192 - accuracy: 0.8230\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.4915 - accuracy: 0.8300\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.4722 - accuracy: 0.8359\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4573 - accuracy: 0.8400\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.4451 - accuracy: 0.8432\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.4348 - accuracy: 0.8471\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4260 - accuracy: 0.8501\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4186 - accuracy: 0.8521\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4113 - accuracy: 0.8551\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.4056 - accuracy: 0.8565\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.3998 - accuracy: 0.8585\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3948 - accuracy: 0.8600\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3901 - accuracy: 0.8618\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3861 - accuracy: 0.8632\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3817 - accuracy: 0.8644\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3781 - accuracy: 0.8666\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3746 - accuracy: 0.8674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb27e60d2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHbPTL7MaP3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "64693f6e-2c3e-4acb-a145-9be097330b67"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.41143482670784\n",
            "Test accuracy: 0.8523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZxrtIL2bBSC",
        "colab_type": "text"
      },
      "source": [
        "Use Sigmoid activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdW2AvWpa5Yy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "f3a8d93d-7013-4628-d06f-cc4f19ab528e"
      },
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb27d01d400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb27d01d400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 2.2712 - accuracy: 0.2774\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 2.1552 - accuracy: 0.5096\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 1.9959 - accuracy: 0.5447\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 1.7702 - accuracy: 0.5560\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 1.5444 - accuracy: 0.5805\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 1.3737 - accuracy: 0.6118\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 1.2515 - accuracy: 0.6385\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 1.1593 - accuracy: 0.6561\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 4s 70us/sample - loss: 1.0857 - accuracy: 0.6714\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 1.0246 - accuracy: 0.6873\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.9724 - accuracy: 0.6970\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 0.9274 - accuracy: 0.7096\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.8881 - accuracy: 0.7182\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.8538 - accuracy: 0.7239\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.8237 - accuracy: 0.7283\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.7972 - accuracy: 0.7325\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.7739 - accuracy: 0.7368\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.7534 - accuracy: 0.7409\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 0.7353 - accuracy: 0.7452\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 0.7191 - accuracy: 0.7477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb27d007908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm-u0TXra5bx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "248796f9-50b1-49b1-f59e-f34036d3461c"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.7257603793144226\n",
            "Test accuracy: 0.7411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG65nVEbbc1C",
        "colab_type": "text"
      },
      "source": [
        "Looking at ReLu, Tanh and Sigmoid, Tanh gave the best test accuracy out of the various activation functions for a batch size of 128. ReLu came in close behind and then Sigmoid doing the worst out of the three activation functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsICSKlpb_d2",
        "colab_type": "text"
      },
      "source": [
        "Given that Tanh did the best, I will now change it's loss function to Categorical Hinge and see how it performs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3lTspgsa5eM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "869ac277-6667-486e-9aa9-4a32f8d66a9f"
      },
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_hinge',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1430: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb27ba02c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb27ba02c80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.9673 - accuracy: 0.4387\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.7743 - accuracy: 0.6430\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 0.6585 - accuracy: 0.6927\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.5916 - accuracy: 0.7391\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.5344 - accuracy: 0.7796\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4870 - accuracy: 0.7966\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4539 - accuracy: 0.8046\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 0.4305 - accuracy: 0.8106\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 0.4130 - accuracy: 0.8158\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3993 - accuracy: 0.8200\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3881 - accuracy: 0.8238\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.3790 - accuracy: 0.8268\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3709 - accuracy: 0.8298\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3640 - accuracy: 0.8335\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3581 - accuracy: 0.8354\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3526 - accuracy: 0.8382\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3477 - accuracy: 0.8398\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.3433 - accuracy: 0.8412\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3391 - accuracy: 0.8429\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3353 - accuracy: 0.8441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb27ba08c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwj-ZQalcOxZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d9bc9247-ef4a-413f-fa25-7212b32162a9"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.35630363883972166\n",
            "Test accuracy: 0.8305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqDGA6eWcsPM",
        "colab_type": "text"
      },
      "source": [
        "Changing the loss function from crossentropy to hinge, gave the model a better test score similarity to training test score, but an overall worse accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHhNH1vyRc2Z",
        "colab_type": "text"
      },
      "source": [
        "Using the full sample as the batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAOTS4INK1IW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "ea583291-bb69-494a-e70f-2c67eeae60fd"
      },
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=X_train.shape[0], epochs=20, verbose=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb283e5d2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb283e5d2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 2.4257 - accuracy: 0.0664\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.3939 - accuracy: 0.0833\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 1s 13us/sample - loss: 2.3657 - accuracy: 0.1060\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.3402 - accuracy: 0.1306\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.3168 - accuracy: 0.1569\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.2951 - accuracy: 0.1796\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.2749 - accuracy: 0.1985\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.2559 - accuracy: 0.2121\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.2380 - accuracy: 0.2235\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.2211 - accuracy: 0.2321\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.2051 - accuracy: 0.2407\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.1899 - accuracy: 0.2490\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.1753 - accuracy: 0.2580\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.1612 - accuracy: 0.2689\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.1475 - accuracy: 0.2807\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.1343 - accuracy: 0.2928\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.1214 - accuracy: 0.3038\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.1088 - accuracy: 0.3151\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.0965 - accuracy: 0.3269\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 1s 12us/sample - loss: 2.0845 - accuracy: 0.3382\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb283ec2f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfnQKve_K1Df",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bde1f69a-3ae7-4f0e-cdf9-d781246e46b8"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 2.0743548831939695\n",
            "Test accuracy: 0.3458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kanrfxO1wOCx",
        "colab_type": "text"
      },
      "source": [
        "The best performance both in training and test sets are achieved using 8 as the mini batch size. Also, looking at the difference between the scores of the training and test sets are relatively similar comparing them to the scores achieved when using 128 as mini batch size. Since the scores achieved when using 128 as the mini batch size are close to those that are achieved when using 8 as the mini batch size, I believe we can go with 8 as the mini batch size not having to worry about overfitting concerns. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8cJFY-wwOCy",
        "colab_type": "text"
      },
      "source": [
        "## Implemented several ANN models with different learning rates for the stochastic gradient descent. Used 128 as my mini batch size.\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbEJ7PH0wOCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "sgd_001 = optimizers.SGD(lr=0.01)\n",
        "sgd_100 = optimizers.SGD(lr=100)\n",
        "sgd_00000001 = optimizers.SGD(lr=0.0000001)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyu5IUSvwOC1",
        "colab_type": "text"
      },
      "source": [
        "### Used 0.01 as the learning rate.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBTTuuGGwOC2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "9ccd72d5-1dff-4b92-b019-83820e0fd3e4"
      },
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer=sgd_001, loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb2828a2620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb2828a2620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 1.1100 - accuracy: 0.6481\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.6629 - accuracy: 0.7757\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.5711 - accuracy: 0.8070\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.5266 - accuracy: 0.8199\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4971 - accuracy: 0.8287\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4781 - accuracy: 0.8345\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4638 - accuracy: 0.8394\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4530 - accuracy: 0.8424\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4424 - accuracy: 0.8470\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4341 - accuracy: 0.8497\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4262 - accuracy: 0.8525\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4199 - accuracy: 0.8543\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4141 - accuracy: 0.8563\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4080 - accuracy: 0.8591\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4023 - accuracy: 0.8611\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3967 - accuracy: 0.8622\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3926 - accuracy: 0.8644\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3880 - accuracy: 0.8658\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3847 - accuracy: 0.8662\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3813 - accuracy: 0.8682\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb2828af240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b0BBh3swOC4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "68bd9ab8-32af-4b50-e02a-dca4de758707"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.431606214928627\n",
            "Test accuracy: 0.8481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m0djK5ywOC6",
        "colab_type": "text"
      },
      "source": [
        "### Used 100 as the learning rate.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDfMBks9wOC7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "8edd07ce-003b-47a5-fae0-0acc697975ac"
      },
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer=sgd_100, loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb281276158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb281276158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 3270197596285131.5000 - accuracy: 0.1016\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 40.1002 - accuracy: 0.1002\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 39.9025 - accuracy: 0.1025\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 40.0014 - accuracy: 0.1005\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 39.9549 - accuracy: 0.0993\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 41.0604 - accuracy: 0.1006\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 40.1691 - accuracy: 0.1004\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 40.2722 - accuracy: 0.1004\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 39.9255 - accuracy: 0.1008\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 39.3169 - accuracy: 0.1004\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 39.6977 - accuracy: 0.0988\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 40.2181 - accuracy: 0.0994\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 39.8514 - accuracy: 0.0999\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 40.7040 - accuracy: 0.1007\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 39.3432 - accuracy: 0.0988\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 40.5785 - accuracy: 0.0984\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 40.5132 - accuracy: 0.1020\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 40.3816 - accuracy: 0.0998\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 40.6227 - accuracy: 0.1000\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 39.8543 - accuracy: 0.0994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb28125ba58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLQBxCYYwOC9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "72b77915-be58-422f-bbe6-dad815b3b718"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 34.339797686767575\n",
            "Test accuracy: 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HNrnJiiwOC_",
        "colab_type": "text"
      },
      "source": [
        "### Used 0.0000001 as the learning rate.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw2fOZwIwOC_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "ce0b2068-4867-48e1-8949-1e5e303e0ab0"
      },
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer=sgd_00000001, loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb27fc5fd90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fb27fc5fd90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 2.3941 - accuracy: 0.0356\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 2.3941 - accuracy: 0.0356\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3940 - accuracy: 0.0357\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 2.3940 - accuracy: 0.0357\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3939 - accuracy: 0.0357\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 2.3939 - accuracy: 0.0357\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 3s 51us/sample - loss: 2.3938 - accuracy: 0.0357\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3938 - accuracy: 0.0357\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 2.3937 - accuracy: 0.0357\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3937 - accuracy: 0.0357\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 2.3936 - accuracy: 0.0357\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3936 - accuracy: 0.0358\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 2.3936 - accuracy: 0.0358\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3935 - accuracy: 0.0358\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3935 - accuracy: 0.0359\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3934 - accuracy: 0.0359\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 35us/sample - loss: 2.3934 - accuracy: 0.0359\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 35us/sample - loss: 2.3933 - accuracy: 0.0359\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3933 - accuracy: 0.0359\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 2.3932 - accuracy: 0.0359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb27fc152b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7SJU_YdwODE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9879fe38-1b64-444f-8da1-a1d74f5fde07"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 2.39337038192749\n",
            "Test accuracy: 0.0359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu2wiS_iwODJ",
        "colab_type": "text"
      },
      "source": [
        "As far as learning rates, the model efficiently converged when using 0.01 as the learning rate. However, it diverged when using 100, because that value deemed to be too large. Using 0.0000001 as the learning rate causes the model to improve very slowly. Hence the accuracy improved very little. So, it deemed to be too low."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEmyCF-EaBbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}